# -*- coding: utf-8 -*-
"""Q1_write_regex.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xAF0AxxQYxwBIyixWEnJjmldYhdet-oS

Problem statement - There are times when a user writes Good, Nice App or any other positive text, in the review and gives 1-star rating. Your goal is to identify the reviews where the semantics of review text does not match rating. 

Your goal is to identify such ratings where review text is good, but rating is negative- so that the support team can point this to users. 

Deploy it using - Flask/Streamlit etc and share the live link. 

Important
In this data app - the user will upload a csv and you would be required to display the reviews where the content doesnâ€™t match ratings.  This csv will be in the same format as the DataSet Link
"""

import pandas as pd
import numpy as np

df= pd.read_csv("C:\Users\Harsha\Downloads\chrome_reviews.csv")

df.head()

df.info()

df.isnull().sum()

df = df.dropna(how = 'all')

df['Star'].unique()

df['Positivity'] = np.where(df['Star'] > 3, 1, 0)
cols = ['ID', 'Star', 'Review URL', 'Thumbs Up', 'User Name', 'Developer Reply', 'Version','Review Date', 'App ID']
df.drop(cols, axis=1, inplace=True)

corpus = []

df['Text'] = df['Text'].astype(str)

df.head()

import re
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

num = len(df)

num

for i in range(0, num):
	
	# column : "Text", row ith
	review = re.sub('[^a-zA-Z]', ' ', df['Text'][i])
	
	# convert all cases to lower cases
	review = review.lower()
	
	# split to array(default delimiter is " ")
	review = review.split()
	
	# creating PorterStemmer object to
	# take main stem of each word
	lemma = WordNetLemmatizer()
	
	# loop for stemming each word
	# in string array at ith row
	review = [lemma.lemmatize(word) for word in review
				if not word in set(stopwords.words('english'))]
				
	# rejoin all string array elements
	# to create back into a string
	review = ' '.join(review)
	
	# append each string to create
	# array of clean text
	corpus.append(review)

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 1000)
X = cv.fit_transform(corpus).toarray()
y = df.iloc[:, 1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)

from xgboost import XGBClassifier

clf = XGBClassifier(random_state=2022)
clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators = 350,criterion = 'entropy')
                             
model.fit(X_train, y_train)
y_pred = model.predict(X_test)


cm = confusion_matrix(y_test, y_pred)
cm

import streamlit as st
st.title("Chrome Reviews - positive reviews with low ratings")



uploaded_file = st.file_uploader("Choose a file for checking review/rating discrepancy")
st.write("Waiting for input")
if uploaded_file is not None:
    
     
     df_test = pd.read_csv(uploaded_file)

df_tNA = df_test.dropna(how = 'all')
df_tNA['Positivity'] = np.where(df_tNA['Star'] > 3, 1, 0)
cols = ['ID', 'Review URL', 'Thumbs Up', 'User Name', 'Developer Reply', 'Version','Review Date', 'App ID']
df_tNA.drop(cols, axis=1, inplace=True)

corpus_test = []
num = len(df_tNA)

df_tNA['Text'] = df_tNA['Text'].astype(str)
# (reviews) rows to clean
for i in range(0, num):
	
	# column : "Text", row ith
	review = re.sub('[^a-zA-Z]', ' ', df_tNA['Text'][i])
	
	# convert all cases to lower cases
	review = review.lower()
	
	# split to array(default delimiter is " ")
	review = review.split()
	
	# creating PorterStemmer object to
	# take main stem of each word
	lemma = WordNetLemmatizer()
	
	# loop for stemming each word
	# in string array at ith row
	review = [lemma.lemmatize(word) for word in review
				if not word in set(stopwords.words('english'))]
				
				

	review = ' '.join(review)
	
	
	corpus_test.append(review)
#print(corpus_test)

cv_test = CountVectorizer(max_features = 1000)
X_testr = cv_test.fit_transform(corpus_test).toarray()
y_testr = df_tNA.iloc[:, 2].values

y_predr = model.predict(X_testr)
cm = confusion_matrix(y_testr, y_predr)

st.write("The list of reviews where the reviews and ratings probably don't match are:")
for i in range(0, len(df_tNA)):
    if(y_predr[i] == 1 and y_testr[i] == 0):
            st.write(df_tNA['Text'][i],df_tNA['Star'][i])